{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7 Day 1: Structured data (AKA: Pandas DataFrames)\n",
    "\n",
    "## Objectives:\n",
    "\n",
    "* Learn to create and read in DataFrames\n",
    "* Learn to use Series\n",
    "* Learn some basic manipulation skills\n",
    "* Learn where to find more information about Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the following table of data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.random.RandomState(42)\n",
    "time = np.linspace(0,2,10)\n",
    "xs = time * .3 + (state.rand(10)-.5)*.1\n",
    "ys = -time**2 + 2*time + (state.rand(10)-.5)*.1\n",
    "print('      time          x          y\\n')\n",
    "for t, x, y in zip(time, xs, ys):\n",
    "    print(f'{t:10.4} {x:10.4} {y:10.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to view and work with this as a coherent single entity. If we chose to use a matrix, we'd have some issues:\n",
    "\n",
    "* Our axes are inherently different - operations along columns make sense, rows... Not so much.\n",
    "* One of the axis has labels (time, x, and y) that we'd lose, making our code harder to read\n",
    "* What happens if we have different data types?\n",
    "* Normal matrix operations (like multiplication) don't really make sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just look at what a Pandas DataFrame would look like, then we'll talk a bit more about them. Note that there are a **ton** of ways to make a DataFrame. And we have some choices we will ignore for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'time': time, 'x': xs, 'y':ys})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our time would make a better index than the default 0,1,2,...,9, so let's try that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('time', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.index = pd.to_timedelta(df.index, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.plot('x', 'y', kind='scatter');\n",
    "df.plot.scatter('x', 'y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to access columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A column is a \"Series\": That's like a 1D array but with an index and possibly a name attached. The Series align on index instead of location - if you add two Series, matching indexed value will add."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `['x']` syntax is more general, but the `.x` syntax is shorter, and much nicer in a notebook. It doesn't work for setting brand new columns, or if the name of a column is not valid in Python or would overwrite an existing property or method.\n",
    "\n",
    "DataFrames and Series follow the array protocol, so numpy operation work on them too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['r'] = np.sqrt(df.x**2 + df.y**2)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames are designed to make it easy to add and operate on columns; you should not in general be adding new rows (this should tell you what the internal memory layout must be like)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can use `.apply` to apply a function to a DataFrame with a bit more control, or `.applymap` to apply a function element-wise to a DataFrame or Series (but the function is a Python function, so the loop must happen in Python so it is slower than `.apply`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas features\n",
    "\n",
    "#### Pandas design:\n",
    "* Make everything as Pythonic as possible. Even if that means there are many ways of doing things.\n",
    "* Design around everyday usage rather than theory\n",
    "\n",
    "#### Features:\n",
    "\n",
    "* **Index** types: Several custom arrays with extra features for types of indexes\n",
    "    * Including hierarchical indexes, which allow multidimensional-like data to be used\n",
    "* **Series**: A 1D array with an attached index\n",
    "    * New types: Powerful datetime and timedelta features, including special calender support, periodic times, etc.\n",
    "    * Categorical support (a bit more powerful than sets)\n",
    "* **DataFrame**: a table of data with indexes and headers\n",
    "* Great input/output support for lots of data formats (`.csv`, Excel, many more)\n",
    "* Great output display, notebook support\n",
    "* Amazing data manipulation\n",
    "* Like Numpy, can be a standard for other statistical packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing and writing a dataframe\n",
    "\n",
    "* See the DataFrame's help for a massive list of options.\n",
    "* Reading in a DataFrame is done with the `pd.read_*` functions.\n",
    "* Writing a DataFrame is done with the `df.to_*` methods.\n",
    "\n",
    "See **Table 5-1: Possible data inputs to DataFrame constructor** in *Python for Data Analysis, 2nd edition*, by Wes McKinney. Also Chapter 6 for reading/writing DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "`df[x]` is a special case - it behaves differently depending on the arguments - columns normally but some cases are rows (such as when using a boolean Series). When doing something specific, use the specialized accessors:\n",
    "\n",
    "* `df[column]`: Select a column\n",
    "* `df.loc[row, column]`: Indexing by names\n",
    "* `df.iloc[row, column]`: Indexing by number\n",
    "* `at` and `iat` are available for single values.\n",
    "\n",
    "Note that using a `list` is different than a `tuple` in an indexing expression in Pandas.\n",
    "\n",
    "#### See Table 5.4 for ways to index a DataFrame\n",
    "\n",
    "Indexing options with DataFrame in *Python for Data Analysis, 2nd edition*, by Wes McKinney."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris dataset\n",
    "Let's look at one of the seaborn datasets (seaborn is a plotting wrapper on MatPlotLib that helps with statistical visualization - but we are just using it's handy example datasets which load in Pandas. Internet required.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset('iris')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things of note:\n",
    "   \n",
    "* No column makes sense as an index here - we'll just leave the numerical index.\n",
    "* We have a categorical column - but it didn't read in as a categorical datatype! That's easy to fix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.species = df.species.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly get some information about the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessors\n",
    "\n",
    "You can use an \"accessor\" (Pandas terminology) to perform operations on series as a specific type:\n",
    "* `.str`: string methods that act on the series\n",
    "* `.cat`: Operations on categories\n",
    "* `.dt`: Datetime operations\n",
    "* `.plot`: Serves two purposes, either acts like a plot function or gives you access to other types of plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.species.str.capitalize().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.species.cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a boolean Series to select rows from a DataFrame (or another Series):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.species == 'setosa'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select just two rows of our table: (Note: this *must* be a list, not a tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['sepal_length', 'sepal_width']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine what we've learned:\n",
    "\n",
    "(notice the automatic x and y axis labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for i, category in enumerate(df.species.cat.categories):\n",
    "    df[df.species == category].plot.scatter('sepal_length', 'sepal_width', label=category, c=f'C{i}', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MatPlotLib now has better support for Pandas, which makes this a bit easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for category in df.species.cat.categories:\n",
    "    ax.scatter('sepal_length', 'sepal_width', data=df[df.species == category], label=category)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could make this even nicer with a groupby, which returns a group you can iterate over to get the name and dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for name, group in df.groupby('species'):\n",
    "    ax.scatter('sepal_length', 'sepal_width', data=group, label=name)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas supports lots more, like database style merges and joins, etc.\n",
    "\n",
    "In general, the best thing to do with Pandas is search and look around to see if the functionality you want is there. Avoid loops and anything that looks ugly until you are sure it's the only what to do what you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas can be seen as similar to:\n",
    "\n",
    "* Excel\n",
    "* R\n",
    "* SQL\n",
    "* SAS\n",
    "* Stata\n",
    "* ROOT (some parts)\n",
    "\n",
    "Learn more at:\n",
    "\n",
    "* [Pandas website](https://pandas.pydata.org)\n",
    "* Our recommended book (available on the UC libraries online)\n",
    "* [10 minutes to Pandas](http://pandas.pydata.org/pandas-docs/stable/10min.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda Python 3.6",
   "language": "python",
   "name": "sys_python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
